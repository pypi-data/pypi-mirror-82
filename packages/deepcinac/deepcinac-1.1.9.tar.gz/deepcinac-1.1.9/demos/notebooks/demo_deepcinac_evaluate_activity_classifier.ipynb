{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_deepcinac_evaluate_activity_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "887T3fJ8L6pZ",
        "colab_type": "text"
      },
      "source": [
        "###DEMO of deepCINAC###\n",
        "\n",
        "Welcome on this notebook. \n",
        "\n",
        "We're going to guide you on how to evaluate the performance of your activity classifier using \"ground truth\" data from a .cinac file. \n",
        "\n",
        "To evaluate the performance of a cell type classifier, check this [notebook](https://gitlab.com/cossartlab/deepcinac/-/blob/master/demos/notebooks/demo_deepcinac_predictions.ipynb) file is available to be run localy. \n",
        "\n",
        "This notebook has been conceived in order to be run on google colab. A [python](https://gitlab.com/cossartlab/deepcinac/tree/master/demos/general/demo_deepcinac_evaluate_activity_classifier.py) file is available to be run localy. \n",
        "\n",
        "Here is a link to our [gitlab page](https://gitlab.com/cossartlab/deepcinac) for more information about our package. \n",
        "\n",
        "To run this code, you will need some neuronal acitivity predictions files obtained using a classifier, you can download some [there](https://bit.ly/2XyNoF5).\n",
        "\n",
        "To evaluate its performances, you need some ground truth. It need to be in the\n",
        ".cinac format, you can obtain it by opening your files in the deepCINAC GUI and\n",
        "save the data. \n",
        "\n",
        "You can also compare other inference method results, such as CaImAn results. \n",
        "\n",
        "The demo will run on the files used to produce the figures in our pre-print. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-KB7EzyNxGp",
        "colab_type": "text"
      },
      "source": [
        "**First** we are installing deepcinac and its depedencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3owIjWCELxCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade deepcinac\n",
        "!pip install scanimage-tiff-reader\n",
        "!pip install tifffile\n",
        "!pip install PyYAML --upgrade\n",
        "!pip install hdf5storage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7uXWd21NhSo",
        "colab_type": "text"
      },
      "source": [
        "Packages imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS4QIGLXNhke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deepcinac.cinac_benchmarks import benchmark_neuronal_activity_inferences\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ZjYsnsN3pU",
        "colab_type": "text"
      },
      "source": [
        "**Accessing your files in google drive**\n",
        "\n",
        "To access your files in google drive, you need to mount it. Running the code below, a link will appear that will give you access. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpXjSDq-N4Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuBPsU5bN6r5",
        "colab_type": "text"
      },
      "source": [
        "You will need to upload your data to your drive. To do so, indicate the paths of the different files on the code below. You may have to replace the 'My Drive' in 'gdrive/My Drive/' by the correct path depending on the language used on your google drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYd9CJ4jN6GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = 'gdrive/My Drive/demo_deepcinac/'\n",
        "\n",
        "# path to calcium imaging data\n",
        "data_path = os.path.join(root_path, \"data\")\n",
        "\n",
        "\"\"\"\n",
        "    directory in which the predictions from a classifier and the cinac files\n",
        "    containin ground truth are.  \n",
        "    the code will produce a boxplot for each inference method (could be a \n",
        "    deepcinac classifier, a human, another algorithm)\n",
        "    each directory in the \"inferences_dir\" will correspond to a different \n",
        "    session\n",
        "    a yaml file in the \"inferences_dir\" will serve to config which session\n",
        "    should be evaluate and which inference should be displayed in the boxplot\n",
        "    use to show the performance of each method \n",
        "    (see examples there: https://bit.ly/2XyNoF5)\n",
        "    \n",
        "    then in each session directory, another yaml file allows to configure\n",
        "    which cells should be used to evaluate the inferences methods. \n",
        "\"\"\"\n",
        "inferences_dir = os.path.join(data_path, \"for_benchmarks\", \"figure_8A\")\n",
        "\n",
        "# path of the directory where the results will be save\n",
        "# a directory will be created each time the prediction is run\n",
        "# the directory name will be the date and time at which the analysis has been run\n",
        "# the predictions will be in this directory.\n",
        "results_path = os.path.join(root_path, \"results\")\n",
        "time_str = datetime.now().strftime(\"%Y_%m_%d.%H-%M-%S\")\n",
        "results_path =  os.path.join(results_path, f\"{time_str}\")\n",
        "os.mkdir(results_path)\n",
        "\n",
        "\"\"\"\n",
        "There are a few options available:\n",
        "- colorfull_boxplots: if True, the boxplots will be colored (one color by boxplot)\n",
        "- white_background: if True white background, else black\n",
        "- with_legend: Add a legend with the name of the session\n",
        "- put_metric_as_y_axis_label: put labels on the y-axis instead that a the top\n",
        "- alpha_scatter: transparency level of the scatter (each scatter correspond to a cell)\n",
        "- save_formats: list of str represent the formats of the figure, could be 'eps',\n",
        "'pdf', 'jpg', 'png'. If multiple formats, there will be as many figures version\n",
        "as formats\n",
        "- using_patch_for_legend: If True one legend by session, otherwise add as many\n",
        "as cells\n",
        "- predictions_stat_by_metrics: if True, produce the figures that shows\n",
        "the distribution of the predictions for each transient\n",
        "- plot_proportion_frames_in_transients: if True produce the figure that shows\n",
        "the proportion of frames predicted in the transients\n",
        "- color_cell_as_boxplot: if True, the cells have the same color of the boxplots,\n",
        "else the cell are colored according to their session, one color by session\n",
        "- with_cells: if True, add cells in addition of the boxplot as a scatter plot\n",
        "- with_cell_number: if True, the cells' number is added \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Outputs: \n",
        "- It will produce boxplots displaying sensitivity, specificity & F1 score\n",
        "- as well as other figures if you put 'predictions_stat_by_metrics' or/and\n",
        "'plot_proportion_frames_in_transients' to True\n",
        "- A Wilcoxon signed-rank test will be applied between each pair of inference\n",
        "methods and the results will be printed (be careful, those might only be valid \n",
        "for large distribution)\n",
        "- Finally the median, 25th and 75th percentile of each metrics distribution \n",
        "will be printed\n",
        "\"\"\"\n",
        "benchmark_neuronal_activity_inferences(inferences_dir=inferences_dir, \n",
        "                                       results_path=results_path,\n",
        "                                       colorfull_boxplots=False, \n",
        "                                       white_background=True,\n",
        "                                       with_legend=True, \n",
        "                                       put_metric_as_y_axis_label=True,\n",
        "                                       alpha_scatter=1, \n",
        "                                       save_formats=[\"png\"],\n",
        "                                       using_patch_for_legend=True, \n",
        "                                       predictions_stat_by_metrics=False,\n",
        "                                       plot_proportion_frames_in_transients=False,\n",
        "                                       color_cell_as_boxplot=False, \n",
        "                                       with_cells=True, \n",
        "                                       with_cell_number=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}